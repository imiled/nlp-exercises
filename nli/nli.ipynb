{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Natural Language Inference\n",
    "\n",
    "In this notebook we're training a NLI system, which is able to identify the logical relationship between a pair of texts: typically, a premise, and a hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    [\"I love pizza and pasta\", \"I love Italian food\", 1],\n",
    "    [\"Tennis matches are long and boring\", \"I don't think tennis is interesting\", 0],\n",
    "    [\"Sushi and ramen are my favorite Japanese dishes\", \"I like Asian food\", 1],\n",
    "    [\"I have a son\", \"I have children\", 1],\n",
    "    [\"I own too many bicycles\", \"You like reading\", 0],\n",
    "    [\"I was born in Madrid\", \"I have French nationality\", 0],\n",
    "]\n",
    "\n",
    "train_df = pd.DataFrame(train_data, columns=[\"text_a\", \"text_b\", \"labels\"])\n",
    "\n",
    "eval_data = [\n",
    "    [\"Sushi and ramen are my favorite Japanese dishes\", \"I like Asian food\", 1],\n",
    "    [\"I love pizza and pasta\", \"I love Italian food\", 1],\n",
    "    [\"Tennis matches are long and boring\", \"I don't think tennis is interesting\", 0],\n",
    "]\n",
    "\n",
    "eval_df = pd.DataFrame(eval_data, columns=[\"text_a\", \"text_b\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "args = {\n",
    "    \"output_dir\": \"outputs/\",\n",
    "    \"cache_dir\": \"cache_dir/\",\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"logging_steps\": 50,\n",
    "    \"save_steps\": 2000,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"reprocess_input_data\": False,\n",
    "    \"evaluate_during_training\": False,\n",
    "    # \"process_count\": cpu_count() - 2 if cpu_count() > 2 else 1,\n",
    "    \"n_gpu\": 1,\n",
    "    \"wandb_project\": \"test-master\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(\n",
    "    \"roberta\", \"roberta-base\", num_labels=2, use_cuda=False, args=args\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df, eval_df=eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(\n",
    "    eval_df, acc=sklearn.metrics.accuracy_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict(\n",
    "    [[\"Tennis matches are long and boring\", \"I don't like tennis\"]]\n",
    ")\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training an Inference System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../datasets/sts/train.tsv\", sep=\"\\t\", error_bad_lines=False)\n",
    "dev = pd.read_csv(\"../datasets/sts/dev.tsv\", sep=\"\\t\", error_bad_lines=False)\n",
    "\n",
    "train = train.rename(\n",
    "    columns={\"sentence1\": \"text_a\", \"sentence2\": \"text_b\", \"score\": \"labels\"}\n",
    ").dropna()\n",
    "\n",
    "dev = dev.rename(\n",
    "    columns={\"sentence1\": \"text_a\", \"sentence2\": \"text_b\", \"score\": \"labels\"}\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "def pearson_corr(preds, labels):\n",
    "    return pearsonr(preds, labels)[0]\n",
    "\n",
    "\n",
    "def spearman_corr(preds, labels):\n",
    "    return spearmanr(preds, labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "args = {\n",
    "    \"output_dir\": \"outputs/\",\n",
    "    \"cache_dir\": \"cache_dir/\",\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 512,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"logging_steps\": 50,\n",
    "    \"save_steps\": 2000,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"reprocess_input_data\": False,\n",
    "    \"evaluate_during_training\": False,\n",
    "    # \"process_count\": cpu_count() - 2 if cpu_count() > 2 else 1,\n",
    "    \"n_gpu\": 1,\n",
    "    \"regression\": True,\n",
    "    \"wandb_project\": \"test-master\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = ClassificationModel(\n",
    "    \"roberta\", \"roberta-base\", use_cuda=False, num_labels=1, args=args\n",
    ")\n",
    "\n",
    "\n",
    "model.train_model(train, pearson_corr=pearson_corr, spearman_corr=spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(\n",
    "    dev, pearson_corr=pearson_corr, spearman_corr=spearman_corr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict([[\"I love ramen and sushi\", \"I like Japanese food\"]])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
