{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Toxic Language Detection on Jigsaw Dataset\n",
    "\n",
    "In this notebook we're training a multi-label text classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from simpletransformers.classification import MultiLabelClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    [\"Pizza and pasta are Italian food\", [1, 1, 0, 0, 0, 0]],\n",
    "    [\"Before start cooking find a good recipe\", [1, 0, 0, 0, 0, 0]],\n",
    "    [\"Cooking is one of my hobbies\", [0, 1, 0, 0, 0, 0]],\n",
    "    [\"I like football\", [0, 0, 1, 1, 0, 0]],\n",
    "    [\"I hate tennis\", [0, 0, 1, 0, 0, 0]],\n",
    "    [\"This year the Olympic Games are held in Tokyo\", [0, 0, 0, 1, 0, 0]],\n",
    "    [\"Natural Language Processing deals with talking machines\", [0, 0, 0, 0, 1, 1]],\n",
    "    [\"Textual entailment and semantic similarity are NLP tasks\", [0, 0, 0, 0, 1, 0]],\n",
    "    [\"NLU stands for natural language understanding\", [0, 0, 0, 0, 0, 1]],\n",
    "]\n",
    "\n",
    "train_df = pd.DataFrame(train_data, columns=[\"text\", \"labels\"])\n",
    "\n",
    "eval_data = [\n",
    "    [\"Cooking is one of my hobbies\", [0, 1, 0, 0, 0, 0]],\n",
    "    [\"I hate tennis\", [0, 0, 1, 0, 0, 0]],\n",
    "    [\"Natural Language Processing deals with talking machines\", [0, 0, 0, 0, 1, 1]],\n",
    "]\n",
    "\n",
    "eval_df = pd.DataFrame(eval_data, columns=[\"text\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "args = {\n",
    "    \"output_dir\": \"outputs/\",\n",
    "    \"cache_dir\": \"cache_dir/\",\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"logging_steps\": 50,\n",
    "    \"save_steps\": 2000,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"reprocess_input_data\": False,\n",
    "    \"evaluate_during_training\": False,\n",
    "    # \"process_count\": cpu_count() - 2 if cpu_count() > 2 else 1,\n",
    "    \"n_gpu\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = MultiLabelClassificationModel(\n",
    "    \"roberta\", \"roberta-base\", num_labels=6, use_cuda=False, args=args\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict([\"This class is about natural language.\"])\n",
    "\n",
    "print(predictions)\n",
    "print(raw_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training a Text Classifier to Detect Toxic Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../datasets/toxic_language/train.csv\")\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# encode the labels in a new column\n",
    "labels = list(\n",
    "    map(\n",
    "        list,\n",
    "        zip(\n",
    "            train[\"toxic\"],\n",
    "            train[\"severe_toxic\"],\n",
    "            train[\"obscene\"],\n",
    "            train[\"threat\"],\n",
    "            train[\"insult\"],\n",
    "            train[\"identity_hate\"],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "train[\"labels\"] = labels\n",
    "\n",
    "# rename and remove other columns\n",
    "train = train.rename(columns={\"comment_text\": \"text\"})\n",
    "train = train.drop(\n",
    "    \"id toxic severe_toxic obscene threat insult identity_hate\".split(), axis=1\n",
    ")\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "args = {\n",
    "    \"output_dir\": \"outputs/\",\n",
    "    \"cache_dir\": \"cache_dir/\",\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"weight_decay\": 0,\n",
    "    \"learning_rate\": 4e-5,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"warmup_ratio\": 0.06,\n",
    "    \"warmup_steps\": 0,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"logging_steps\": 50,\n",
    "    \"save_steps\": 2000,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"reprocess_input_data\": False,\n",
    "    \"evaluate_during_training\": False,\n",
    "    # \"process_count\": cpu_count() - 2 if cpu_count() > 2 else 1,\n",
    "    \"n_gpu\": 1,\n",
    "    \"wandb_project\": \"test-master\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = MultiLabelClassificationModel(\n",
    "    \"roberta\", \"roberta-base\", num_labels=6, use_cuda=False, args=args\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(model_outputs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict([\"You fucking idiot!!\"])\n",
    "\n",
    "print(predictions)\n",
    "print(raw_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## A Quick Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def load_model(\n",
    "    model_architecture: str,\n",
    "    directory: str = \"outputs/\",\n",
    "    num_labels: int = 6,\n",
    "    use_cuda: bool = False,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Loads a pre-trained model\"\"\"\n",
    "    model = MultiLabelClassificationModel(\n",
    "        model_architecture, directory, num_labels=6, use_cuda=use_cuda, args=kwargs\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def detect_toxic_lang(line, text):\n",
    "    \"\"\"Prints predictions of a Text Classifier\"\"\"\n",
    "    predictions, raw_outputs = model.predict([text])\n",
    "    return predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f0d93fc1cb406cbbc3a0275381b386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671543d7bb9c466eb61ce8edf203a790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%detect_toxic_lang\n",
    "Hello, sir. How is your day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c665e213da504336bccba81a7b4dbb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948bfe5d4d624290b19f2989c9dd1728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%detect_toxic_lang\n",
    "Only nigga that I trust is me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
